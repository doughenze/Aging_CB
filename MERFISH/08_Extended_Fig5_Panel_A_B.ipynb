{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7a828c-ed9a-4926-9e34-f8682f4c827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gseapy as gp\n",
    "from tqdm import tqdm\n",
    "from adjustText import adjust_text\n",
    "import seaborn as sns\n",
    "import anndata\n",
    "\n",
    "from sklearn.neighbors import BallTree, KDTree\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "from tqdm import tqdm\n",
    "from joblib import delayed, Parallel\n",
    "import os\n",
    "from scipy.stats import ranksums, zscore\n",
    "from itertools import combinations\n",
    "from nheatmap import nhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953709c8-1451-4a4b-b7e6-8d4d322f0b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cells_within_radius(adata,cell_type_col,target_cell, radius=10):\n",
    "    \"\"\"\n",
    "    Find all cells within a given radius (in microns) of Granule cells in a spatial seq anndata object.\n",
    "\n",
    "    Parameters:\n",
    "    adata : AnnData\n",
    "        Annotated data matrix.\n",
    "    radius : float\n",
    "        Radius in microns to search for neighboring cells. Default is 10 microns.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame\n",
    "        DataFrame with indices of cells within the given radius of Granule cells.\n",
    "    \"\"\"\n",
    "    new_adata = adata.copy()\n",
    "    new_adata.obs.set_index('Name', inplace=True)\n",
    "    # Extract coordinates and batch IDs\n",
    "    x_coords = new_adata.obs['x'].values\n",
    "    y_coords = new_adata.obs['y'].values\n",
    "    batch_ids = new_adata.obs['batchID'].values\n",
    "    cell_types = new_adata.obs[cell_type_col]\n",
    "    \n",
    "    new_adata.obs[f\"peri_{target_cell}\"] = False\n",
    "\n",
    "    granule_indices = np.where(cell_types == target_cell)[0]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Iterate through each Granule cell and find neighboring cells\n",
    "    for granule_idx in tqdm(granule_indices, desc=\"Processing Peri Granule Cells\"):\n",
    "        granule_x = x_coords[granule_idx]\n",
    "        granule_y = y_coords[granule_idx]\n",
    "        granule_batch = batch_ids[granule_idx]\n",
    "\n",
    "        # Calculate distances to all other cells in the same batch\n",
    "        same_batch_indices = np.where(batch_ids == granule_batch)[0]\n",
    "        same_batch_x = x_coords[same_batch_indices]\n",
    "        same_batch_y = y_coords[same_batch_indices]\n",
    "\n",
    "        distances = np.sqrt((same_batch_x - granule_x)**2 + (same_batch_y - granule_y)**2)\n",
    "\n",
    "        within_radius_indices = same_batch_indices[np.where(distances <= radius)[0]]\n",
    "\n",
    "        new_adata.obs.iloc[within_radius_indices, new_adata.obs.columns.get_loc(f\"peri_{target_cell}\")] = True\n",
    "\n",
    "    return new_adata\n",
    "\n",
    "\n",
    "def shift_log_normalized(adata):\n",
    "    \"\"\"\n",
    "    Shift log-normalized values to be non-negative.\n",
    "    \n",
    "    Parameters:\n",
    "    adata : AnnData\n",
    "        Annotated data matrix.\n",
    "    \n",
    "    Returns:\n",
    "    AnnData\n",
    "        AnnData object with shifted log-normalized values.\n",
    "    \"\"\"\n",
    "    adata_copy = adata.copy()\n",
    "    min_val = adata_copy.X.min()\n",
    "    if min_val < 0:\n",
    "        adata_copy.X = adata_copy.X - min_val\n",
    "    return adata_copy\n",
    "\n",
    "def differential_expression(adata1, adata2, shift_log_values=True):\n",
    "    \"\"\"\n",
    "    Perform differential expression analysis between two AnnData objects.\n",
    "\n",
    "    Parameters:\n",
    "    adata1 : AnnData\n",
    "        First annotated data matrix.\n",
    "    adata2 : AnnData\n",
    "        Second annotated data matrix.\n",
    "    shift_log_values : bool\n",
    "        Whether to shift log-normalized values to be non-negative.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame\n",
    "        DataFrame containing differential expression results.\n",
    "    \"\"\"\n",
    "    # Add a column indicating the origin of each cell\n",
    "    adata1.obs['group'] = 'group1'\n",
    "    adata2.obs['group'] = 'group2'\n",
    "\n",
    "    if shift_log_values:\n",
    "        adata1 = shift_log_normalized(adata1)\n",
    "        adata2 = shift_log_normalized(adata2)\n",
    "\n",
    "    # Concatenate the two AnnData objects\n",
    "    adata_combined = adata1.concatenate(adata2, batch_key='batch', batch_categories=['group1', 'group2'])\n",
    "\n",
    "    # Perform differential expression analysis using Scanpy\n",
    "    sc.tl.rank_genes_groups(adata_combined, groupby='batch', reference='group1', method='wilcoxon')\n",
    "\n",
    "    # Extract results into a DataFrame\n",
    "    results = adata_combined.uns['rank_genes_groups']\n",
    "    groups = results['names'].dtype.names\n",
    "    pvals = pd.DataFrame({group + '_pvals': results['pvals'][group] for group in groups})\n",
    "    pvals_adj = pd.DataFrame({group + '_pvals_adj': results['pvals_adj'][group] for group in groups})\n",
    "    logfoldchanges = pd.DataFrame({group + '_logfoldchanges': results['logfoldchanges'][group] for group in groups})\n",
    "    names = pd.DataFrame({group + '_names': results['names'][group] for group in groups})\n",
    "\n",
    "    return pd.concat([names, pvals, pvals_adj, logfoldchanges], axis=1)\n",
    "\n",
    "def plot_volcano(\n",
    "    df, \n",
    "    sig_lfc=0.5, \n",
    "    group='group2', \n",
    "    pval_col_suffix='_pvals', \n",
    "    logfc_col_suffix='_logfoldchanges', \n",
    "    name_col_suffix='_names', \n",
    "    title='Volcano Plot', \n",
    "    xlims=None, \n",
    "    savefig=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a volcano plot for differential expression analysis results.\n",
    "\n",
    "    Parameters:\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing differential expression results.\n",
    "    group : str\n",
    "        Group name for differential expression results.\n",
    "    pval_col_suffix : str\n",
    "        Suffix for the p-value column in the DataFrame.\n",
    "    logfc_col_suffix : str\n",
    "        Suffix for the log fold change column in the DataFrame.\n",
    "    name_col_suffix : str\n",
    "        Suffix for the gene names column in the DataFrame.\n",
    "    title : str\n",
    "        Title for the plot.\n",
    "    xlims : tuple, optional\n",
    "        Limits for the x-axis.\n",
    "    savefig : str, optional\n",
    "        Path to save the figure.\n",
    "\n",
    "    Returns:\n",
    "    list, list\n",
    "        Two lists containing significant genes with log fold change < 1 and > 1.\n",
    "    \"\"\"\n",
    "    pvals = df[group + pval_col_suffix]\n",
    "    logfoldchanges = df[group + logfc_col_suffix]\n",
    "    gene_names = df[group + name_col_suffix]\n",
    "    \n",
    "    # Define significance thresholds\n",
    "    sig_pval = 0.05\n",
    "    sig_logfc = sig_lfc\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(logfoldchanges, -np.log10(pvals), color='grey', alpha=0.5, label='NS')\n",
    "    \n",
    "    # Highlight significant points\n",
    "    sig_points = (pvals < sig_pval) & (np.abs(logfoldchanges) > sig_logfc)\n",
    "    plt.scatter(logfoldchanges[sig_points], -np.log10(pvals[sig_points]), color='red', alpha=0.50, label='P-value and log2 FC')\n",
    "    plt.scatter(logfoldchanges[(pvals < sig_pval) & ~sig_points], -np.log10(pvals[(pvals < sig_pval) & ~sig_points]), color='blue', alpha=0.50, label='P-value')\n",
    "    plt.scatter(logfoldchanges[~(pvals < sig_pval) & (np.abs(logfoldchanges) > sig_logfc)], -np.log10(pvals[~(pvals < sig_pval) & (np.abs(logfoldchanges) > sig_logfc)]), color='green', alpha=0.50, label='Log2 FC')\n",
    "    \n",
    "    plt.axhline(y=-np.log10(sig_pval), color='black', linestyle='--')\n",
    "    plt.axvline(x=sig_logfc, color='black', linestyle='--')\n",
    "    plt.axvline(x=-sig_logfc, color='black', linestyle='--')\n",
    "    \n",
    "    # Annotate significant genes\n",
    "    texts = []\n",
    "    sig_genes_less_than_1 = []  # List for significant genes with logFC < 1\n",
    "    sig_genes_greater_than_1 = []  # List for significant genes with logFC > 1\n",
    "\n",
    "    for i in range(len(gene_names)):\n",
    "        if sig_points[i]:\n",
    "            if logfoldchanges[i] < -1*sig_lfc:\n",
    "                sig_genes_less_than_1.append(gene_names[i])\n",
    "            elif logfoldchanges[i] > sig_lfc:\n",
    "                sig_genes_greater_than_1.append(gene_names[i])\n",
    "\n",
    "            texts.append(plt.text(logfoldchanges[i], -np.log10(pvals[i]), gene_names[i], fontsize=8))\n",
    "    \n",
    "    adjust_text(texts, arrowprops=dict(arrowstyle='-', color='black'))\n",
    "    \n",
    "    plt.xlabel('Log2 fold change')\n",
    "    plt.ylabel('-Log10 P-value')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    if xlims is not None:\n",
    "        plt.xlim(xlims)\n",
    "        \n",
    "    if savefig is not None:\n",
    "        plt.savefig(savefig, format='pdf')\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    return sig_genes_less_than_1, sig_genes_greater_than_1\n",
    "\n",
    "def add_activated_microglia_column(adata, cell_type_col='updated_celltype', cd9_threshold=9):\n",
    "    \"\"\"\n",
    "    Add a column 'activated_microglia' to the AnnData object to mark activated microglia cells.\n",
    "    \n",
    "    Parameters:\n",
    "    adata : AnnData\n",
    "        Annotated data matrix.\n",
    "    cell_type_col : str\n",
    "        Column name in adata.obs that contains the cell type information.\n",
    "    trem2_threshold : float\n",
    "        Expression threshold for Trem2.\n",
    "    cd9_threshold : float\n",
    "        Expression threshold for Cd9.\n",
    "    \n",
    "    Returns:\n",
    "    AnnData\n",
    "        AnnData object with an added 'activated_microglia' column in adata.obs.\n",
    "    \"\"\"\n",
    "    # Ensure Trem2 and Cd9 are in the var_names\n",
    "    if 'Trem2' not in adata.var_names or 'Cd9' not in adata.var_names:\n",
    "        raise ValueError(\"Trem2 and/or Cd9 are not present in the var_names of the AnnData object.\")\n",
    "    \n",
    "    # Initialize the 'activated_microglia' column with False\n",
    "    adata.obs['activated_microglia'] = False\n",
    "\n",
    "    # Check conditions and update the 'activated_microglia' column\n",
    "    microglia_mask = adata.obs[cell_type_col] == 'Microglia'\n",
    "    #trem2_expression = adata[:, 'Trem2'].X > trem2_threshold\n",
    "    cd9_expression = adata[:, 'Cd9'].X > cd9_threshold\n",
    "\n",
    "    activated_mask = microglia_mask & cd9_expression.flatten()# & trem2_expression.flatten()\n",
    "    adata.obs.loc[activated_mask, 'activated_microglia'] = True\n",
    "\n",
    "    return adata\n",
    "\n",
    "def compute_binned_values(dists, scores, min_d=0, max_d=100, bin_size=30):\n",
    "    binned_mean = np.zeros(max_d-min_d-bin_size)\n",
    "    binned_std = np.zeros(max_d-min_d-bin_size)\n",
    "    scores = np.array(scores)\n",
    "    for i in np.arange(min_d, max_d-bin_size):\n",
    "        # find distances in this bin range\n",
    "        idx = np.argwhere(np.logical_and(dists>i, dists<=(i+bin_size)))\n",
    "        curr_scores = scores[idx.flatten().tolist()]\n",
    "        binned_mean[i] = np.mean(curr_scores)#/len(idx)\n",
    "        binned_std[i] = np.std(curr_scores)/np.sqrt(len(curr_scores))#/len(idx)\n",
    "    binned_mean -= binned_mean.mean()\n",
    "    binned_std -= binned_mean.mean()\n",
    "    return binned_mean, binned_std\n",
    "def identify_nearest_neighbors_with_dist(X,Y, min_dist=0):\n",
    "    if X.shape[0] > 0 and Y.shape[0] > 0:\n",
    "        kdtree = KDTree(Y)\n",
    "        dists, ind = kdtree.query(X, k=2,return_distance=True)\n",
    "        good_dists = np.zeros(len(dists))\n",
    "        good_ind = np.zeros(len(ind))\n",
    "        for i in range(dists.shape[0]):\n",
    "            if dists[i,0] > 0: # remove duplicates\n",
    "                good_dists[i] = dists[i,0]\n",
    "                good_ind[i] = ind[i,0]\n",
    "            else:\n",
    "                good_dists[i] = dists[i,1]\n",
    "                good_ind[i] = ind[i,1]\n",
    "        #ind_X = np.hstack([[i]*len(ind[i]) for i in np.arange(len(ind)) if len(ind[i])>0])\n",
    "        return good_dists, good_ind\n",
    "    else:\n",
    "        return np.array([])\n",
    "\n",
    "def compute_celltype_obs_distance_correlation(A,cell_type_X, cell_type_Y, obs_key_X, batch_key='batchID', celltype_key1='subclass_label_transfer', celltype_key2='subclass_label_transfer'):\n",
    "    all_obs_X = []\n",
    "    all_dists_Y = []\n",
    "\n",
    "    # Iterate over each unique batch\n",
    "    for batch in A.obs[batch_key].unique():\n",
    "        # Filter by batch\n",
    "        batch_data = A[A.obs[batch_key] == batch]\n",
    "\n",
    "        # Filter by cell types within the batch\n",
    "        X = batch_data[batch_data.obs[celltype_key1] == cell_type_X]\n",
    "        Y = batch_data[batch_data.obs[celltype_key2] == cell_type_Y]\n",
    "\n",
    "        # Extract the observed variable and spatial coordinates\n",
    "        obs_X = X.obs[obs_key_X]\n",
    "        curr_X = X.obsm['spatial']\n",
    "        curr_Y = Y.obsm['spatial']\n",
    "\n",
    "        # Compute the distances and indices of nearest neighbors within the batch\n",
    "        dists_Y, ind_Y = identify_nearest_neighbors_with_dist(curr_X, curr_Y)\n",
    "\n",
    "        # Store the results\n",
    "        all_obs_X.extend(obs_X.values)\n",
    "        all_dists_Y.extend(dists_Y)\n",
    "\n",
    "    return all_obs_X, all_dists_Y\n",
    "\n",
    "def plot_violin_with_stats(adata, score_column, split_by, hue_by=None, save_path=None):\n",
    "    \"\"\"\n",
    "    Plots violin plots for a module score and performs pairwise Wilcoxon rank-sum tests.\n",
    "\n",
    "    Parameters:\n",
    "    - adata: AnnData object containing the data.\n",
    "    - score_column: Column name in adata.obs with the module scores.\n",
    "    - split_by: Column name in adata.obs to split the violin plots by.\n",
    "    - hue_by: Column name in adata.obs to hue the violin plots by (optional).\n",
    "\n",
    "    Returns:\n",
    "    - results_df: Pandas DataFrame containing pairwise comparisons and p-values.\n",
    "    \"\"\"\n",
    "    if score_column not in adata.obs:\n",
    "        raise ValueError(f\"{score_column} not found in adata.obs\")\n",
    "    if split_by not in adata.obs:\n",
    "        raise ValueError(f\"{split_by} not found in adata.obs\")\n",
    "    if hue_by and hue_by not in adata.obs:\n",
    "        raise ValueError(f\"{hue_by} not found in adata.obs\")\n",
    "\n",
    "    # Create violin plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.violinplot(\n",
    "        data=adata.obs,\n",
    "        x=split_by,\n",
    "        y=score_column,\n",
    "        hue=hue_by if hue_by else None,\n",
    "        split=True if hue_by else False,\n",
    "        inner=\"quart\",\n",
    "        palette=\"Set2\" if hue_by else None\n",
    "    )\n",
    "    plt.title(f\"Violin plot of {score_column} split by {split_by}\" + (f\" and hued by {hue_by}\" if hue_by else \"\"))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, format='pdf')\n",
    "    plt.show()\n",
    "\n",
    "    # Pairwise comparisons\n",
    "    results = []\n",
    "    if hue_by:\n",
    "        unique_categories = adata.obs.groupby([split_by, hue_by]).groups.keys()\n",
    "    else:\n",
    "        unique_categories = adata.obs[split_by].unique()\n",
    "    for cat1, cat2 in combinations(unique_categories, 2):\n",
    "        if hue_by:\n",
    "            subset1 = adata.obs[\n",
    "                (adata.obs[split_by] == cat1[0]) & (adata.obs[hue_by] == cat1[1])\n",
    "            ][score_column]\n",
    "            subset2 = adata.obs[\n",
    "                (adata.obs[split_by] == cat2[0]) & (adata.obs[hue_by] == cat2[1])\n",
    "            ][score_column]\n",
    "        else:\n",
    "            subset1 = adata.obs[adata.obs[split_by] == cat1][score_column]\n",
    "            subset2 = adata.obs[adata.obs[split_by] == cat2][score_column]\n",
    "\n",
    "        # Skip comparisons with empty subsets\n",
    "        if subset1.empty or subset2.empty:\n",
    "            continue\n",
    "\n",
    "        stat, p_value = ranksums(subset1, subset2)\n",
    "        results.append({\n",
    "            \"Group 1\": cat1,\n",
    "            \"Group 2\": cat2,\n",
    "            \"Statistic\": stat,\n",
    "            \"P-value\": p_value\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "def create_pseudobulk(adata, cluster_col='Age', batch_col='batchID'):\n",
    "    # Create a unique identifier for each cluster-batch pair\n",
    "    adata.obs['pseudobulk_id'] = adata.obs['Brain_Region'].astype(str) +'.'+ adata.obs['subclass_label_transfer'].astype(str) + '.' + adata.obs[batch_col].astype(str)\n",
    "    \n",
    "    # Group the data by the pseudobulk_id\n",
    "    groups = adata.obs['pseudobulk_id'].unique()\n",
    "    pseudobulk_data = []\n",
    "    pseudobulk_obs = []\n",
    "    \n",
    "    for group in groups:\n",
    "        # Subset the data for each group\n",
    "        group_mask = adata.obs['pseudobulk_id'] == group\n",
    "        group_data = adata[group_mask, :].X.mean(axis=0)  # Sum the expression values\n",
    "        pseudobulk_data.append(group_data)\n",
    "        \n",
    "        # Collect the metadata\n",
    "        region, celltype, batch = group.split('.')\n",
    "        pseudobulk_obs.append({'pseudobulk_id': group, 'batchID': batch, 'Brain_Region': region , 'celltype': celltype})\n",
    "    \n",
    "    # Convert the list to a numpy array\n",
    "    pseudobulk_data = np.array(pseudobulk_data)\n",
    "    #print(pseudobulk_data[:,0,:].shape)\n",
    "    #print(pseudobulk_data.shape)\n",
    "    \n",
    "    # Create a new AnnData object for the pseudobulked data\n",
    "    pseudobulk_adata = sc.AnnData(X=pseudobulk_data[:,0,:])\n",
    "    \n",
    "    # Add the metadata\n",
    "    pseudobulk_adata.obs = pd.DataFrame(pseudobulk_obs)\n",
    "    \n",
    "    # Copy variable names (genes) from the original data\n",
    "    pseudobulk_adata.var = adata.var.copy()\n",
    "    \n",
    "    return pseudobulk_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4427443-6a61-499e-af15-875eb43495b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad('ABC_cleaned.h5ad')\n",
    "adata = adata[adata.obs.subclass_label_confidence > 0.8]\n",
    "Cerebellum = adata[(adata.obs.Brain_Region == 'Cerebellum')].copy()\n",
    "Hippocampus = adata[(adata.obs.Brain_Region == 'Hippocampus')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df368ad6-1e13-4c26-94ac-758ed3cf7775",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_viz_hipp = cells_within_radius(Hippocampus,'subclass_label_transfer','DG Glut', radius=30)\n",
    "ad_viz_cer = cells_within_radius(Cerebellum,'subclass_label_transfer','CB Granule Glut', radius=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e670a6ed-4382-4e18-b02c-d7f3cba36cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming the cell types of interest\n",
    "important_cerebellar_cell_types = [\n",
    "    \"Bergmann NN\",\n",
    "    \"Astro-CB NN\",\n",
    "    \"Oligo NN\",\n",
    "    \"OPC NN\",\n",
    "    \"Microglia NN\"\n",
    "]\n",
    "\n",
    "hippocampal_cell_types = [\n",
    "    \"Astro-NT NN\",\n",
    "    \"Microglia NN\",\n",
    "    \"Oligo NN\",\n",
    "    \"OPC NN\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da94e19-9073-4417-91ff-f1239b18e000",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_subset_cb = ad_viz_cer[(ad_viz_cer.obs['subclass_label_transfer'].isin(important_cerebellar_cell_types)) & (ad_viz_cer.obs['peri_CB Granule Glut'])].copy()# & (ad_viz_cer.obs.Age == '24')].copy()\n",
    "adata_subset_hp = ad_viz_hipp[(ad_viz_hipp.obs['subclass_label_transfer'].isin(hippocampal_cell_types)) & (ad_viz_hipp.obs['peri_DG Glut'])].copy()\n",
    "\n",
    "adata_combined = adata_subset_hp.concatenate(adata_subset_cb, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a6fc04-a5d6-4456-a433-5fd3e4961e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_combined.X = adata_combined.layers['counts'].copy()\n",
    "sc.pp.normalize_total(adata_combined,target_sum=1e4)\n",
    "sc.pp.log1p(adata_combined)\n",
    "\n",
    "adata_subset_cb.X = adata_subset_cb.layers['counts'].copy()\n",
    "sc.pp.normalize_total(adata_subset_cb,target_sum=1e4)\n",
    "sc.pp.log1p(adata_subset_cb)\n",
    "\n",
    "adata_subset_hp.X = adata_subset_hp.layers['counts'].copy()\n",
    "sc.pp.normalize_total(adata_subset_hp,target_sum=1e4)\n",
    "sc.pp.log1p(adata_subset_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22db71c6-39b3-4168-8b15-2ebd649d2723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to show that the signal clusters microglia by the granules and not other glial cell types\n",
    "\n",
    "pseudo = create_pseudobulk(adata_combined[(adata_combined.obs.Age == '24')])# & (adata_combined_peri.obs.Brain_Region == 'Cerebellum')])\n",
    "pseudo_sub = pseudo[:,['Cdk2', 'Cxcl2', 'Slamf9', 'Arhgap5', 'Ctss', 'Atp2a3', 'H2-K1']]\n",
    "counts_matrix = pseudo_sub.X\n",
    "gene_names = pseudo_sub.var_names\n",
    "cell_names = pseudo_sub.obs_names\n",
    "\n",
    "# Create the DataFrame with obs_names as rows and var_names as columns\n",
    "counts_df = pd.DataFrame(data=counts_matrix, index=cell_names, columns=gene_names)\n",
    "zscored_df = counts_df.apply(zscore, axis=0)\n",
    "\n",
    "subset_df = zscored_df\n",
    "\n",
    "dfc = pseudo.obs.loc[:,['celltype','Brain_Region']]#,'peri']]\n",
    "dfr = pseudo.obs.loc[:,['celltype','Brain_Region']]#,'peri']]\n",
    "\n",
    "#dfr_sorted = dfr.sort_values(by='Brain_Region')\n",
    "\n",
    "# Reorder `subset_df` to match the order of `dfr_sorted`\n",
    "#subset_df_reordered = subset_df.loc[dfr_sorted.index]\n",
    "\n",
    "cmaps={ 'peri':'RdYlGn', 'celltype':'Set2',\n",
    "        'PC score':'gist_heat', 'Brain_Region':'rainbow'}\n",
    "\n",
    "clipped_data = subset_df.clip(upper=2,lower= -2)\n",
    "g = nhm(data=clipped_data,dfr=dfr, figsize=(15, 15), linewidths=0, cmaps=cmaps, showxticks=True,cmapCenter='coolwarm')\n",
    "g.hcluster(method='single', metric='cosine', optimal_ordering=False)\n",
    "fig, plots = g.run()\n",
    "fig.savefig('score_specific/old_microglia_hp_y_cb_no_endo.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20331e3f-9ad8-42a2-8082-de802e685a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to show how the score changes with age amongst the cerebellar cell types\n",
    "sc.pp.scale(adata_subset_cb)\n",
    "sc.tl.score_genes(adata_subset_cb,gene_list=['Cdk2', 'Cxcl2', 'Slamf9', 'Arhgap5', 'Ctss', 'Atp2a3', 'H2-K1'],score_name='prox_score')\n",
    "results_df = plot_violin_with_stats(adata_subset_cb, 'prox_score', 'subclass_label_transfer',hue_by='Age',save_path='score_specific/cb_prox_score_by_ct_age.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Vizgen_2",
   "language": "python",
   "name": "vizgen_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
