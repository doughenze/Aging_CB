{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb314e8b-6a55-4dd8-8f8e-ae380e4361cd",
   "metadata": {},
   "source": [
    "This code is derived from these repositories:\n",
    "\n",
    "https://github.com/xingjiepan/MERFISH_analysis/tree/main/cell_cell_contact\n",
    "\n",
    "https://github.com/ZhuangLab/whole_mouse_brain_MERFISH_atlas_scripts_2023/blob/main/scripts/cell_cell_contacts/get_significant_contacts_30um.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63eb8058-4eea-4662-930b-2d3556862365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "sc.settings.n_jobs = 56\n",
    "sc.settings.set_figure_params(dpi=180, dpi_save=300, frameon=False, figsize=(4, 4), fontsize=8, facecolor='white')\n",
    "\n",
    "import sys\n",
    "from permutation import generate_cell_type_contact_count_matrices\n",
    "import scipy.cluster\n",
    "import scipy.stats\n",
    "import statsmodels.stats.multitest\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "373bad2b-0ba6-4278-ac72-0525d8d1742c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/doug.henze/.conda/envs/Vizgen_2/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:207: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "/home/doug.henze/.conda/envs/Vizgen_2/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:234: UserWarning: Some cells have zero counts\n",
      "  warn(UserWarning(\"Some cells have zero counts\"))\n"
     ]
    }
   ],
   "source": [
    "adata = sc.read_h5ad('../../MERFISH/Baysor/ABC_cleaned.h5ad')\n",
    "\n",
    "#wanting to make sure we only show the neurons with a high confidence\n",
    "adata_HQ = adata[adata.obs.subclass_label_confidence > 0.8]\n",
    "\n",
    "adata_HQ.X = adata_HQ.layers['counts'].toarray().copy()\n",
    "sc.pp.normalize_total(adata_HQ)\n",
    "sc.pp.log1p(adata_HQ)\n",
    "\n",
    "# just placing the region-age pairs in .csvs to look at later\n",
    "for ages in adata_HQ.obs.Age.unique():\n",
    "    for regions in adata_HQ.obs.Brain_Region.unique():\n",
    "        adata_HQ[(adata_HQ.obs.Age == ages) & (adata_HQ.obs.Brain_Region == regions)].obs.to_csv(f'contacts/{regions + ages}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1acf0a1a-29be-48b6-9810-c3eb9f9cb3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'outputs_30um'\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed0dcd18-150f-4555-9aaf-fb2752a9e923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cerebellum\n",
      "Count for 3-mo-female-1-rev2\n",
      "Count for 3-mo-female-2\n",
      "Count for 3-mo-female-3\n",
      "Count for 3-mo-male-1\n",
      "Count for 3-mo-male-2\n",
      "Count for 3-mo-male-3-rev2\n",
      "Cerebellum\n",
      "Count for 24-mo-female-1\n",
      "Count for 24-mo-female-3\n",
      "Count for 24-mo-female-5\n",
      "Count for 24-mo-male-2\n",
      "Count for 24-mo-male-4-rev2\n",
      "Hippocampus\n",
      "Count for 3-mo-female-1-rev2\n",
      "Count for 3-mo-female-2\n",
      "Count for 3-mo-female-3\n",
      "Count for 3-mo-male-2\n",
      "Count for 3-mo-male-3-rev2\n",
      "Hippocampus\n",
      "Count for 24-mo-female-1\n",
      "Count for 24-mo-female-3\n",
      "Count for 24-mo-female-5\n",
      "Count for 24-mo-male-1\n",
      "Count for 24-mo-male-2\n",
      "Count for 24-mo-male-4-rev2\n"
     ]
    }
   ],
   "source": [
    "# This code is heavily adapted from the cited repos\n",
    "major_brain_regions = [\"Cerebellum\",\"Hippocampus\"]\n",
    "ages = ['3','24']\n",
    "\n",
    "for region in major_brain_regions:\n",
    "    for age in ages:\n",
    "        print(region)\n",
    "    \n",
    "        # Read the data\n",
    "        df_ct_labels = pd.read_csv(os.path.join('contacts', f'{region+age}.csv'), index_col=0)\n",
    "        slice_ids = np.unique(df_ct_labels['batchID'])\n",
    "    \n",
    "        cell_type_col = 'subclass_label_transfer'\n",
    "        cell_types = np.unique(df_ct_labels[cell_type_col])\n",
    "        N_cell_types = len(cell_types)\n",
    "        N_permutations = 1000\n",
    "    \n",
    "    # Count and save the contacts without permutation\n",
    "        merged_contact_counts = np.zeros((N_cell_types, N_cell_types), dtype=int)\n",
    "\n",
    "        for slice_id in slice_ids:\n",
    "            print(f'Count for {slice_id}')\n",
    "            df_slice = df_ct_labels[df_ct_labels['batchID'] == slice_id]\n",
    "            cell_type_contact_counts = generate_cell_type_contact_count_matrices(df_slice, cell_type_col, \n",
    "                                        ['aligned_x', 'aligned_y'], cell_types, \n",
    "                                        permutation_method='no_permutation', contact_radius=30)\n",
    "    \n",
    "            merged_contact_counts = merged_contact_counts + cell_type_contact_counts\n",
    "    \n",
    "        output_file = os.path.join(output_path, f'{region+age}_no_permutation.npy')\n",
    "        np.save(output_file, merged_contact_counts)\n",
    "    \n",
    "        from multiprocessing import Pool\n",
    "\n",
    "        def permute_and_count_contacts_for_slices(df_slice_list):\n",
    "            merged_contact_counts = np.zeros((N_permutations, N_cell_types, N_cell_types), dtype=int)\n",
    "            for df_slice in df_slice_list:\n",
    "            \n",
    "                for i in range(N_permutations):\n",
    "                    df_slice_rand = df_slice.copy()\n",
    "                \n",
    "                    r_permute = 100\n",
    "                    r = r_permute * np.sqrt(np.random.uniform(size=df_slice_rand.shape[0]))\n",
    "                    theta = np.random.uniform(size=df_slice_rand.shape[0]) * 2 * np.pi\n",
    "                \n",
    "                    df_slice_rand['aligned_x'] += r * np.sin(theta)\n",
    "                    df_slice_rand['aligned_y'] += r * np.cos(theta)\n",
    "            \n",
    "                    cell_type_contact_counts = generate_cell_type_contact_count_matrices(df_slice_rand, cell_type_col, \n",
    "                                        ['aligned_x', 'aligned_y'], cell_types, \n",
    "                                        permutation_method='no_permutation', contact_radius=30)\n",
    "            \n",
    "            \n",
    "                    merged_contact_counts[i] = merged_contact_counts[i] + cell_type_contact_counts\n",
    "        \n",
    "            return merged_contact_counts\n",
    "    \n",
    "    # Get the dataframe for each slice\n",
    "        all_df_slice_list = [df_ct_labels[df_ct_labels['batchID'] == slice_id] for slice_id in slice_ids]\n",
    "\n",
    "    # Split the slices into groups\n",
    "        N_groups = 48\n",
    "        group_size = int(np.ceil(len(slice_ids) / N_groups))\n",
    "        grouped_slice_dfs = []\n",
    "\n",
    "        for i in range(N_groups):\n",
    "            slice_id_start = i * group_size\n",
    "            slice_id_stop = (i + 1) * group_size\n",
    "            grouped_slice_dfs.append(all_df_slice_list[slice_id_start:slice_id_stop])\n",
    "    \n",
    "    # Permute and count the contacts in parallel\n",
    "        N_permutations = 1000\n",
    "        with Pool(N_groups) as p:\n",
    "            contact_analysis_results = p.map(permute_and_count_contacts_for_slices, grouped_slice_dfs)\n",
    "    \n",
    "        merged_contact_counts = np.sum(contact_analysis_results, axis=0)\n",
    "    \n",
    "        means = np.mean(merged_contact_counts, axis=0)\n",
    "        stds = np.std(merged_contact_counts, axis=0)\n",
    "    \n",
    "        np.save(os.path.join(output_path, f'{region+age}_local_permutation_count_tensor.npy'),\n",
    "            merged_contact_counts)\n",
    "    \n",
    "        output_file_mean = os.path.join(output_path, f'{region+age}_local_permutation_mean.npy')\n",
    "        np.save(output_file_mean, means)\n",
    "        output_file_std = os.path.join(output_path, f'{region+age}_local_permutation_std.npy')\n",
    "        np.save(output_file_std, stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e46e8b55-6360-49c8-a841-ef568dab2328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_zero_pairs(contact_mtx):\n",
    "    n_0 = 0\n",
    "    for i in range(contact_mtx.shape[0]):\n",
    "        for j in range(i, contact_mtx.shape[0]):\n",
    "            if contact_mtx[i, j] == 0:\n",
    "                n_0 += 1\n",
    "    return n_0\n",
    "\n",
    "def adjust_p_value_matrix_by_BH(p_val_mtx):\n",
    "    '''Adjust the p-values in a matrix by the Benjamini/Hochberg method.\n",
    "    The matrix should be symmetric.\n",
    "    '''\n",
    "    p_val_sequential = []\n",
    "    N = p_val_mtx.shape[0]\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(i, N):\n",
    "            p_val_sequential.append(p_val_mtx[i, j])\n",
    "\n",
    "    p_val_sequential_bh = statsmodels.stats.multitest.multipletests(p_val_sequential, method='fdr_bh')[1]\n",
    "    \n",
    "    adjusted_p_val_mtx = np.zeros((N, N))\n",
    "    \n",
    "    counter = 0\n",
    "    for i in range(N):\n",
    "        for j in range(i, N):\n",
    "            adjusted_p_val_mtx[i, j] = p_val_sequential_bh[counter]\n",
    "            adjusted_p_val_mtx[j, i] = p_val_sequential_bh[counter]\n",
    "            counter += 1\n",
    "            \n",
    "    return adjusted_p_val_mtx\n",
    "\n",
    "def get_data_frame_from_metrices(cell_types, mtx_dict):\n",
    "    N = len(cell_types)\n",
    "    \n",
    "    serials_dict = {'cell_type1':[], 'cell_type2':[]}\n",
    "    for k in mtx_dict.keys():\n",
    "        serials_dict[k] = []\n",
    "        \n",
    "    for i in range(N):\n",
    "        for j in range(i, N):\n",
    "            serials_dict['cell_type1'].append(cell_types[i])\n",
    "            serials_dict['cell_type2'].append(cell_types[j])\n",
    "            for k in mtx_dict.keys():\n",
    "                serials_dict[k].append(mtx_dict[k][i, j])\n",
    "                \n",
    "    return pd.DataFrame(serials_dict)\n",
    "    \n",
    "\n",
    "def sort_cell_type_contact_p_values(p_val_mtx, cell_types):\n",
    "    '''Return a list of (cell_type1, cell_type2, p_value) sorted by p_values.'''\n",
    "    p_val_list = []\n",
    "    N = p_val_mtx.shape[0]\n",
    "    for i in range(N):\n",
    "        for j in range(i, N):\n",
    "            p_val_list.append((cell_types[i], cell_types[j], p_val_mtx[i, j]))\n",
    "    return sorted(p_val_list, key=lambda x:x[2])\n",
    "def get_optimal_order_of_mtx(X):\n",
    "    Z = scipy.cluster.hierarchy.ward(X)\n",
    "    return scipy.cluster.hierarchy.leaves_list(\n",
    "        scipy.cluster.hierarchy.optimal_leaf_ordering(Z, X))\n",
    "\n",
    "def get_ordered_tick_labels(tick_labels):\n",
    "    tick_labels_with_class = [s.split(' ')[-1] + ' ' + s for s in tick_labels]\n",
    "    return np.argsort(tick_labels_with_class)\n",
    "\n",
    "def filter_pval_mtx(pval_mtx, tick_labels, allowed_pairs):\n",
    "    pval_mtx_filtered = pval_mtx.copy()\n",
    "    \n",
    "    for i in range(pval_mtx.shape[0]):\n",
    "        ct1 = tick_labels[i]\n",
    "        for j in range(pval_mtx.shape[1]):\n",
    "            ct2 = tick_labels[j]\n",
    "            \n",
    "            if ((ct1, ct2) in allowed_pairs) or ((ct2, ct1) in allowed_pairs):\n",
    "                continue\n",
    "            else:\n",
    "                pval_mtx_filtered[i, j] = 1\n",
    "            \n",
    "    return pval_mtx_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "977de172-bb0d-4f47-9502-933d3b04cd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we created our .npy files we can utilize them to count our observed vs theoretical contacts\n",
    "# This code is also heavily inspired by the cited repos\n",
    "permutation_path = 'outputs_30um'\n",
    "\n",
    "major_brain_regions = [\"Cerebellum\",\"Hippocampus\"]\n",
    "\n",
    "result_dfs = []\n",
    "\n",
    "for region in major_brain_regions:\n",
    "    for age in ages:\n",
    "    \n",
    "    # Load the cell type labels\n",
    "        df_ct_labels = pd.read_csv(os.path.join('contacts', f'{region+age}.csv'), index_col=0)\n",
    "\n",
    "        subclass_types = np.unique(df_ct_labels['subclass_label_transfer'])\n",
    "    \n",
    "        cell_contact_counts = np.load(os.path.join(permutation_path, f'{region+age}_no_permutation.npy'))\n",
    "\n",
    "        local_null_means = np.load(os.path.join(permutation_path, f'{region+age}_local_permutation_mean.npy'))\n",
    "        local_null_stds = np.load(os.path.join(permutation_path, f'{region+age}_local_permutation_std.npy'))\n",
    "\n",
    "    # Require all stds to be larger or equal to the minimal observable std value\n",
    "        local_null_stds = np.maximum(local_null_stds, np.sqrt(1 / 1000))\n",
    "    \n",
    "        local_z_scores = (cell_contact_counts - local_null_means) / local_null_stds\n",
    "        local_p_values = scipy.stats.norm.sf(local_z_scores)\n",
    "        adjusted_local_p_values = adjust_p_value_matrix_by_BH(local_p_values)\n",
    "    \n",
    "        fold_changes = cell_contact_counts / (local_null_means + 1e-4)\n",
    "        filled_region = np.full(adjusted_local_p_values.shape, region)\n",
    "        filled_age = np.full(adjusted_local_p_values.shape, age)\n",
    "    \n",
    "    #make_dotplot(local_p_values, fold_changes, subclass_types, title=region)\n",
    "    #make_dotplot(adjusted_local_p_values, fold_changes, subclass_types, title=region)\n",
    "    #make_dotplot(adjusted_local_p_values, fold_changes, subclass_types, title=region + ' L-R filtered', \n",
    "    #             allowed_pairs=allowed_pairs)\n",
    "        \n",
    "    # Gather all results into a data frame\n",
    "        contact_result_df = get_data_frame_from_metrices(subclass_types, \n",
    "                                             {'pval-adjusted': adjusted_local_p_values,\n",
    "                                              'pval': local_p_values,\n",
    "                                              'z_score': local_z_scores,\n",
    "                                              'contact_count': cell_contact_counts,\n",
    "                                              'permutation_mean': local_null_means,\n",
    "                                              'permutation_std': local_null_stds,\n",
    "                                              'region': filled_region,\n",
    "                                              'age': filled_age\n",
    "                                            }).sort_values('z_score', ascending=False)\n",
    "\n",
    "    # Filter out pairs that don't contact\n",
    "    # notably we are not evaluating p-values yet\n",
    "        contact_result_df = contact_result_df[contact_result_df['contact_count'] > 0]\n",
    "        contact_result_df.to_csv(os.path.join(permutation_path, f'{region+age}_close_contacts.csv'))\n",
    "    \n",
    "        result_dfs.append(contact_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af7c7513-4487-4af4-b63e-d5b21b1943b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I want to compare the difference between 24 and 3 versus what we would expect it to be randomly\n",
    "# We will then use this to filter p-values\n",
    "\n",
    "combined_results = pd.concat(result_dfs)\n",
    "df_age3 = combined_results[combined_results['age'] == '3']\n",
    "df_age24 = combined_results[combined_results['age'] == '24']\n",
    "\n",
    "# Merge the dataframes on cell_type1, cell_type2, and region\n",
    "merged_df = pd.merge(df_age3, df_age24, on=['cell_type1', 'cell_type2', 'region'], suffixes=('_3', '_24'))\n",
    "\n",
    "# Calculate the z-statistic for the differences in contact_count\n",
    "merged_df['z_statistic'] = (merged_df['contact_count_24'] - merged_df['contact_count_3']) / \\\n",
    "                           (merged_df['permutation_std_3']**2 + merged_df['permutation_std_24']**2)**0.5\n",
    "merged_df['p_value'] = scipy.stats.norm.sf(abs(merged_df['z_statistic'])) * 2\n",
    "\n",
    "merged_df['p_value_adj'] = statsmodels.stats.multitest.multipletests(merged_df['p_value'].values, method='fdr_bh')[1]\n",
    "\n",
    "merged_df_trim = merged_df[merged_df.p_value_adj < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56609e3c-e4d4-43fa-be13-e68697a2a76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to save this new dataframe on a per region basis\n",
    "# new output permutation path\n",
    "permutation_path = 'outputs_30um_age'\n",
    "os.makedirs(permutation_path, exist_ok=True)\n",
    "for region in major_brain_regions:\n",
    "    contact_result_df = merged_df_trim[merged_df_trim.region == region]\n",
    "    contact_result_df.to_csv(os.path.join(permutation_path, f'{region}_close_contacts.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c686d4-08ab-436b-91c4-6e3d30dafc11",
   "metadata": {},
   "source": [
    "# Now we want to count contacts for the Cerebellum and Hippocampus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1081ae82-e30c-4331-8676-3144db14abea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cerebellum = pd.read_csv('outputs_30um_age/Cerebellum_close_contacts.csv', index_col=0)\n",
    "Hippocampus = pd.read_csv('outputs_30um_age/Hippocampus_close_contacts.csv', index_col=0)\n",
    "\n",
    "Cerebellum['Region'] = 'Cerebellum'\n",
    "Hippocampus['Region'] = 'Hippocampus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57230bab-83db-4a76-888f-ac95cb3d05ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "def calculate_ratio_distribution(df, dist1_mean_col = 'permutation_mean_24', dist1_std_col = 'permutation_std_24', dist2_mean_col = 'permutation_mean_3',\n",
    "                                 dist2_std_col = 'permutation_std_3',real_mean_1='contact_count_24',real_mean_2='contact_count_3'):\n",
    "    \"\"\"\n",
    "    Calculate the mean and standard deviation of the ratio of two distributions.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame containing distribution parameters.\n",
    "    dist1_mean_col (str): Column name for the mean of distribution 1.\n",
    "    dist1_std_col (str): Column name for the standard deviation of distribution 1.\n",
    "    dist2_mean_col (str): Column name for the mean of distribution 2.\n",
    "    dist2_std_col (str): Column name for the standard deviation of distribution 2.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with additional columns `ratio_mean` and `ratio_std`.\n",
    "    \"\"\"\n",
    "    # Extract values\n",
    "    dist1_mean = df[dist1_mean_col]\n",
    "    dist1_std = df[dist1_std_col]\n",
    "    dist2_mean = df[dist2_mean_col]\n",
    "    dist2_std = df[dist2_std_col]\n",
    "    \n",
    "    real1_mean = df[real_mean_1]\n",
    "    real2_mean = df[real_mean_2]\n",
    "\n",
    "    # Compute ratio mean    \n",
    "    ratio_mean = dist1_mean / dist2_mean\n",
    "    ratio_real = real1_mean / real2_mean\n",
    "\n",
    "    # Compute ratio standard deviation using the delta method\n",
    "    ratio_std = np.sqrt(\n",
    "        (dist1_std / dist2_mean) ** 2 + \n",
    "        (dist1_mean * dist2_std / dist2_mean ** 2) ** 2\n",
    "    )\n",
    "\n",
    "    # Calculate z-scores\n",
    "    z_score = (ratio_real - ratio_mean) / ratio_std\n",
    "\n",
    "    # Calculate two-tailed p-values\n",
    "    p_value = 2 * (1 - norm.cdf(np.abs(z_score)))\n",
    "\n",
    "    # Add results to the DataFrame\n",
    "    df = df.copy()  # Avoid modifying the original DataFrame\n",
    "    df['ratio_real'] = ratio_real\n",
    "    df['ratio_mean'] = ratio_mean\n",
    "    df['ratio_std'] = ratio_std\n",
    "    df['z_score'] = z_score\n",
    "    df['p_value'] = p_value\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46ff65b0-3d81-4d5a-876b-9bd539d90a90",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# values were exported and plotted in Prism as ratio_mean and ratio_std\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mCB\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCerebellum_proximity_scores.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m HP\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHippocampus_proximity_scores.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CB' is not defined"
     ]
    }
   ],
   "source": [
    "# values were exported and plotted in Prism as ratio_mean and ratio_std\n",
    "CB.to_csv('Cerebellum_proximity_scores.csv')\n",
    "HP.to_csv('Hippocampus_proximity_scores.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Vizgen_2",
   "language": "python",
   "name": "vizgen_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
